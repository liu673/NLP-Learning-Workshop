{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TF-IDF\n",
    "\n",
    "TF-IDF（Term Frequency–Inverse Document Frequency）是一种用于信息检索与文本挖掘的常用加权技术。TF-IDF可以帮助筛选出在文档中具有重要意义的词汇，常用于关键词提取、文档相似度计算和文本分类等任务。\n",
    "\n",
    "TF-IDF 是一种统计方法，用以评估一字词对于一个文档集或一个语料库中的其中一份文档的重要程度。字词的重要性随着它在文档中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。简单的解释为，一个单词在一个文档中出现次数很多，同时在其他文档中出现此时较少，那么我们认为这个单词对该文档是非常重要的。\n",
    "\n",
    "TF（Term Frequency，词频），某个词条在文中出现的次数。\n",
    "- $词频（TF）=某个词在文档中出现的次数/文档的总词数$\n",
    "IDF（Inverse Document Frequency，逆向文档频率）\n",
    "- $逆文档频率（IDF）=log(语料库的文档总数/(包含该词的文档数+1))$\n",
    "\n",
    "[NLP--词频统计和TF-IDF总结【实践】](https://blog.csdn.net/liu_673/article/details/130509959?spm=1001.2014.3001.5502)\n",
    "\n",
    "## 优点与缺点\n",
    "优点：\n",
    "\n",
    "● 简单易实现。\n",
    "● 考虑了词的重要性，减少了常见但不重要的词（如“的”、“与”等）的权重。\n",
    "● 适用于自然语言处理中的多种任务，如文本分类、文本聚类、信息检索等。\n",
    "\n",
    "缺点：\n",
    "\n",
    "● 对于大型文档集，由于词汇量庞大，生成的 TF-IDF 矩阵往往非常稀疏，所以计算效率不高。\n",
    "● 只考虑了词汇的出现频率，而忽略了词汇在文本中的顺序信息。\n",
    "● 没有考虑词汇之间的语义关系。\n",
    "● TF-IDF 的计算方式导致它的效果依赖于足够大的文档集，数据量不足可能导致效果不佳。\n",
    "\n",
    "## 应用场景\n",
    "\n",
    "● 关键词提取\n",
    "● 文档相似度计算\n",
    "● 信息检索\n",
    "● 文本分类"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       John      Mary      also  football    games.     likes   moives,  \\\n0  0.125000  0.175683  0.000000  0.000000  0.000000  0.250000  0.175683   \n1  0.142857  0.000000  0.200781  0.200781  0.200781  0.142857  0.000000   \n\n         to      too.     watch  \n0  0.125000  0.175683  0.125000  \n1  0.142857  0.000000  0.142857  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>John</th>\n      <th>Mary</th>\n      <th>also</th>\n      <th>football</th>\n      <th>games.</th>\n      <th>likes</th>\n      <th>moives,</th>\n      <th>to</th>\n      <th>too.</th>\n      <th>watch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.125000</td>\n      <td>0.175683</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n      <td>0.175683</td>\n      <td>0.125000</td>\n      <td>0.175683</td>\n      <td>0.125000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.142857</td>\n      <td>0.000000</td>\n      <td>0.200781</td>\n      <td>0.200781</td>\n      <td>0.200781</td>\n      <td>0.142857</td>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.000000</td>\n      <td>0.142857</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# 读取文件路径\n",
    "file_path = os.path.join(\"./data\", \"corpus.txt\")\n",
    "\n",
    "# 从文件中读取语料库\n",
    "with open(file_path, encoding=\"utf-8\") as f:\n",
    "    corpus = f.readlines()\n",
    "\n",
    "# 构建词汇表\n",
    "vocab = sorted(set(\" \".join(corpus).split()))\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# 计算文档频率\n",
    "doc_freq = {word: 0 for word in vocab}\n",
    "for sentence in corpus:\n",
    "    unique_words = set(sentence.split())\n",
    "    for word in unique_words:\n",
    "        if word in doc_freq:\n",
    "            doc_freq[word] += 1\n",
    "\n",
    "# 计算逆文档频率(IDF)\n",
    "num_docs = len(corpus)\n",
    "# idf = {word: math.log(num_docs / (1 + df)) + 1  for word, df in doc_freq.items()}\n",
    "idf = {word: math.log((1 + num_docs) / (1 + df)) + 1 for word, df in doc_freq.items()}\n",
    "# 平滑处理：在计算 IDF 时，分母加 1，以避免除零错误，并确保 IDF 值始终大于 0\n",
    "\n",
    "# 将文本转换为TF-IDF表示\n",
    "def text_to_tfidf(text, idf, vocab_size, word_to_idx):\n",
    "    tfidf = [0] * vocab_size\n",
    "    words = text.split()\n",
    "\n",
    "    # 计算词频(TF)\n",
    "    word_count = {}\n",
    "    for word in words:\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "\n",
    "    # 计算TF-IDF\n",
    "    for word, count in word_count.items():\n",
    "        if word in idf:\n",
    "            idx = word_to_idx[word]\n",
    "            tfidf[idx] = (count / len(words)) * idf[word]\n",
    "\n",
    "    return tfidf\n",
    "\n",
    "# 将语料库中的每句话转换为TF-IDF表示\n",
    "tfidf_corpus = [text_to_tfidf(sentence, idf, vocab_size, word_to_idx) for sentence in corpus]\n",
    "\n",
    "# 打印TF-IDF表示结果\n",
    "# for sentence, tfidf in zip(corpus, tfidf_corpus):\n",
    "#     print(f\"句子: '{sentence.strip()}'\")\n",
    "#     print(f\"词汇: {vocab}\")\n",
    "#     print(f\"TF-IDF表示: {tfidf}\")\n",
    "\n",
    "df_tfidf = pd.DataFrame(tfidf_corpus, columns=vocab)\n",
    "df_tfidf\n",
    "\n",
    "# 如果想将结果保存到CSV文件中，可以使用以下代码\n",
    "# df_tfidf.to_csv('tfidf_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       John     Mary      also  football     games     likes   moives  \\\n0  0.278143  0.39092  0.000000  0.000000  0.000000  0.556286  0.39092   \n1  0.317404  0.00000  0.446101  0.446101  0.446101  0.317404  0.00000   \n\n         to      too     watch  \n0  0.278143  0.39092  0.278143  \n1  0.317404  0.00000  0.317404  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>John</th>\n      <th>Mary</th>\n      <th>also</th>\n      <th>football</th>\n      <th>games</th>\n      <th>likes</th>\n      <th>moives</th>\n      <th>to</th>\n      <th>too</th>\n      <th>watch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.278143</td>\n      <td>0.39092</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.556286</td>\n      <td>0.39092</td>\n      <td>0.278143</td>\n      <td>0.39092</td>\n      <td>0.278143</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.317404</td>\n      <td>0.00000</td>\n      <td>0.446101</td>\n      <td>0.446101</td>\n      <td>0.446101</td>\n      <td>0.317404</td>\n      <td>0.00000</td>\n      <td>0.317404</td>\n      <td>0.00000</td>\n      <td>0.317404</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 使用TfidfVectorizer初始化一个TF-IDF向量化器\n",
    "vectorizer = TfidfVectorizer(stop_words=None, lowercase=False)\n",
    "\n",
    "# 学习语料库并进行向量化\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# 获取词汇表\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 打印每条记录的TF-IDF值\n",
    "# for sentence, tfidf in zip(corpus, X.toarray()):\n",
    "#     print(f\"句子: '{sentence.strip()}'\")\n",
    "#     print(f\"{vocab}\")\n",
    "#     print(f\"TF-IDF表示: \\n{tfidf}\\n\")\n",
    "df = pd.DataFrame(X.toarray(), columns=vocab)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
