{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "在NLP领域，如何将单词数值化呢，One-Hot编码就是一种很简单的方式。假设我们现在有单词数量为 $\\mathbf{N}$ 的词表，那可以生成一个长度为 $\\mathbf{N}$ 的向量来表示一个单词，在这个向量中该单词对应的位置数值为1，其余单词对应的位置数值全部为0。\n",
    "\n",
    "在文本向量化中，One-Hot编码的分类数据一般为单词或字符，以下以单词为例。通过这种编码方式，每个唯一的单词都用一个向量表示。向量的长度等于词汇表的单词数量，其中只有一个位置为1，其余位置都为0。这种表达 式生成的是稀疏向量，其中每个单词都由一个唯一的二进制向量表示，该向量中只有一个高位（1），其他都是低位（0）。\n",
    "\n",
    "## 优点与缺点\n",
    "\n",
    "优点：\n",
    "● 简单快捷\n",
    "\n",
    "缺点：\n",
    "● 数据稀疏、耗时耗空间、不能很好地展示词与词之间的相似关系，且还未考虑到词出现的频率，因而无法区别词的重要性\n",
    "● 词汇表偏大时会导致向量维度过高，从而造成内存使用量偏大\n",
    "\n",
    "One-hot 的基本假设是词之间的语义和语法关系是相互独立的，仅仅从两个向量是无法看出两个词汇之间的关系的，这种独立性不适合词汇语义的运算（向量之间是正交的，向量之间的点积为0，因此无法直接通过向量计算的方式来得出单词之间的关系。）\n",
    "维度爆炸问题，随着词典规模的增大，句子构成的词袋模型的维度变得越来越大，矩阵也变得超稀疏，这种维度的爆增，会大大耗费计算资源\n",
    "\n",
    "## 应用场景\n",
    "\n",
    "● One-Hot编码通常用于文本处理的初始阶段或单词量相对较小的情况。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./images/img.png\" alt=\"Image\" style=\"display: block; margin-left: auto; margin-right: auto; width: 400px;\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子: 'John likes to watch moives, Mary likes too.'\n",
      "One-hot 编码:\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "句子: 'John also likes to watch football games.'\n",
      "One-hot 编码:\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 文本数据\n",
    "# corpus = [\"The cat sat the mat\", \"The dog ate my homework\"]\n",
    "# 没有去除标点符号\n",
    "file_path = os.path.join(\"./data\", \"corpus.txt\")\n",
    "with open(file_path, encoding=\"utf-8\") as f:\n",
    "    corpus = f.readlines()\n",
    "\n",
    "# 构建词汇表\n",
    "vocab = sorted(set(\" \".join(corpus).split()))\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "# 将文本转换为索引\n",
    "def text_to_indices(text, word_to_idx):\n",
    "    return [word_to_idx[word] for word in text.split()]\n",
    "\n",
    "\n",
    "# 将语料库中的每句话转换为索引\n",
    "indices_corpus = [text_to_indices(sentence, word_to_idx) for sentence in corpus]\n",
    "# 获取词汇表大小\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# print(\"词汇表:\", vocab)\n",
    "# print(\"索引映射:\", word_to_idx)\n",
    "# print(\"转换后的索引:\", indices_corpus)\n",
    "\n",
    "\n",
    "# 将索引转换为 one-hot 编码\n",
    "def indices_to_one_hot(indices, vocab_size):\n",
    "    one_hot_encoded = np.zeros((len(indices), vocab_size))\n",
    "    one_hot_encoded[np.arange(len(indices)), indices] = 1\n",
    "    return one_hot_encoded\n",
    "\n",
    "\n",
    "# 将语料库中的每个句子转换为 one-hot 编码\n",
    "one_hot_corpus = [indices_to_one_hot(indices, vocab_size) for indices in indices_corpus]\n",
    "# print(\"one-hot 编码后的语料库:\", one_hot_corpus)\n",
    "\n",
    "# 打印 one-hot 编码结果\n",
    "for sentence, one_hot_sentence in zip(corpus, one_hot_corpus):\n",
    "    print(f\"句子: '{sentence.strip()}'\")\n",
    "    print(\"One-hot 编码:\")\n",
    "    print(one_hot_sentence)\n",
    "# df = pd.DataFrame(one_hot_corpus[0], columns=vocab)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子: 'John likes to watch moives, Mary likes too.'\n",
      "One-hot 编码:\n",
      "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
      "句子: 'John also likes to watch football games.'\n",
      "One-hot 编码:\n",
      "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "\n",
    "# 将索引转换为 one-hot 编码\n",
    "def indices_to_one_hot(indices, vocab_size):\n",
    "    one_hot_encoded = [one_hot(torch.tensor(idx), num_classes=vocab_size) for idx in indices]\n",
    "    return torch.stack(one_hot_encoded)\n",
    "\n",
    "\n",
    "# 将语料库中的每个句子转换为 one-hot 编码\n",
    "one_hot_corpus = [indices_to_one_hot(indices, vocab_size) for indices in indices_corpus]\n",
    "\n",
    "# 打印 one-hot 编码结果\n",
    "for sentence, one_hot_sentence in zip(corpus, one_hot_corpus):\n",
    "    print(f\"句子: '{sentence.strip()}'\")\n",
    "    print(\"One-hot 编码:\")\n",
    "    print(one_hot_sentence)\n",
    "\n",
    "# df1 = pd.DataFrame(one_hot_corpus[0].numpy(), columns=vocab)\n",
    "# df1\n",
    "# df2 = pd.DataFrame(one_hot_corpus[1].numpy(), columns=vocab)\n",
    "# df2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mynlp_project",
   "language": "python",
   "display_name": "MyNLP_Project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
