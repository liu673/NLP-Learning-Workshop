{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FastText\n",
    "\n",
    "FastText是由Facebook的人工智能研究团队开发的一种用于文本分类和词向量表示的开源库，适用于大规模数据集和高性能需求的任务。FastText的相关论文由Piotr Bojanowski等人在2016年发表，FastText的作者认为之前的文本向量化方法没有考虑单词内部的子词之间的关系，所以性能受限。为了改善这个限制，FastText的核心原理包括两大部分：**词向量表示和文本分类**。\n",
    "\n",
    "## 词向量表示\n",
    "\n",
    "FastText 的一个关键创新在于利用了子词信息（Subword Information），即将每个单词表示为多个 n-gram 的组合。\n",
    "\n",
    "例如，单词 \"where\" 可以分解为\"wh\", \"whe\", \"her\", \"ere\", \"re\"等 n-gram。这种方法使得模型能够捕捉到词的子词信息，从而更好地处理未登录词和拼写错误。FastText 使用基于在上文中提到的Skip-Gram的方法来训练embedding。值得注意的是，FastText不仅使用单词本身，还使用单词的所有n-gram。每个单词被表示为它所有n-gram向量的组合。为了提高计算效率，FastText 使用分层Softmax代替传统的Softmax。分层Softmax将所有类别组织成一棵二叉树，每个叶节点对应一个类别。通过减少类别数量的对数级计算，分层Softmax极大地加速了训练和预测过程。\n",
    "\n",
    "## 文本分类原理\n",
    "\n",
    "在文本分类任务中，FastText通过将文本表示为一系列词向量的平均来生成文档向量。对于一个文本d中的每个词w，其向量表示为vw。文本d的表示为所有词向量的平均，即：\n",
    "$$\n",
    "v_d = \\frac{1}{|d|} \\sum_{w \\in d} v_w\n",
    "$$\n",
    "FastText使用线性分类器来进行文本分类。文本向量vd通过一个全连接层，并使用Softmax函数来输出类别概率。分类模型的公式为\n",
    "$$\n",
    "y=Softmax(W \\cdot v_d + b)\n",
    "$$\n",
    "其中W是权重矩阵，b是偏置项\n",
    "\n",
    "## 优缺点\n",
    "优点：\n",
    "\n",
    "● 训练和预测速度也很快，适合实时应用。\n",
    "● 能够处理具有大量类别的任务，并保持高效性。\n",
    "● 支持多种语言的文本处理。\n",
    "\n",
    "缺点：\n",
    "● 使用静态词向量，无法捕捉上下文相关的词义变化。\n",
    "\n",
    "## 应用场景\n",
    "● 文本分类\n",
    "● 关键词提取\n",
    "● 拼写错误纠正"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
